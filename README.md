## Важные детали

- В датасете присутствуют заказы, которые были отменены даже при том условии, что цена была такой же, которую предлагал пользователь
  - Добавлена переменная для учёта этих данных

## Добавленные переменные

- bid_matches_start_price
  - бинарный признак, который показывает, совпала ли цена водителя с ценой пользователя.
  - Теперь модель сможет анализировать зависимость. Например, она может обнаружить, что когда bid_matches_start_price == 1, а заказ все равно отменяется, это часто связано с другими факторами (например, низкий рейтинг водителя или очень большое время подачи). Этот признак добавляет в модель новый пласт информации.
- price_per_meter
- price_per_second
- price_increase_abs
- price_increase_perc

- driver_experience_days
- driver_experience_years

- order_hour
- order_dayofweek
- is_night

## Удалённые переменные

- is_done - целевая колонна
- order_id
- user_id
- tender_id
- tender_timestamp
- order_timestamp
- driver_reg_date (заменена менее персональными данными)
- driver_id
- order_datetime (заменена менее персональными данными)

## Алгоритм построения и оптимизации модели

Для решения задачи классификации был разработан комплексный пайплайн, включающий несколько ключевых этапов, направленных на обеспечение высокого качества данных, подбор оптимальной конфигурации модели и предотвращение переобучения.

### 1. Предобработка и очистка данных

Начальный этап направлен на устранение ошибок и артефактов в исходном датасете для повышения его качества и консистентности. Были выполнены следующие шаги:

- Устранение артефактов вычислений: Исправлены ошибки, возникающие при делении на ноль (например, в полях price_per_meter), путем присвоения таким значениям логичного нуля.
- Удаление аномальных и нелогичных записей: Из набора данных были удалены строки с заведомо некорректными значениями, такими как отрицательный опыт водителя или поездки с практически нулевой дистанцией и длительностью.

### 2. Инженерия признаков

Для улучшения предсказательной силы модели и снижения "шума" в данных был применен метод группировки редких категорий:

- Группировка редких категорий: В категориальных признаках, таких как carmodel и carname, значения, встречающиеся в датасете менее 10 раз, были объединены в общую категорию "Other". Это позволяет модели не переобучаться на единичных, статистически незначимых примерах и находить более общие закономерности.

### 3. Подбор оптимальных гиперпараметров (Optuna)

Вместо ручного подбора "настроек" модели был использован фреймворк Optuna для автоматизированного и интеллектуального поиска.

- Интеллектуальный поиск: Optuna применяет байесовские методы оптимизации для эффективного исследования пространства гиперпараметров (learning_rate, max_depth, l2_leaf_reg и др.).

- Целевая метрика: Целью поиска была максимизация F1-score для класса 1 на отложенной валидационной выборке. Это гарантирует, что подбирается конфигурация, наилучшим образом решающая задачу выявления более редкого, но важного класса.

### 4. Обучение финальной модели (CatBoost)

В качестве основного алгоритма был выбран CatBoost — мощная реализация градиентного бустинга, обладающая рядом преимуществ.

- Обучение на лучших параметрах: Финальная модель обучалась на полной обучающей выборке с использованием лучшей комбинации гиперпараметров, найденной Optuna.

- Ранняя остановка (Early Stopping): В процессе обучения применялся механизм ранней остановки. Модель прекращала обучение, как только ее производительность на валидационной выборке переставала улучшаться в течение 50 итераций. Это позволило:

  - Избежать переобучения, повысив обобщающую способность модели.

  - Автоматически определить оптимальное количество деревьев (n_estimators), делая процесс более эффективным.

### 5. Оптимизация порога классификации (Threshold Tuning)

Финальным шагом стала тонкая настройка решающего правила модели. Вместо стандартного порога вероятности (0.5) был найден оптимальный.

- Поиск лучшего порога: Модель предсказывает вероятности принадлежности к классу 1. Был выполнен перебор пороговых значений от 0.1 до 0.9 с шагом 0.01.

- Выбор по F1-score: Был выбран тот порог, который обеспечил максимальный F1-score для класса 1 на тестовой выборке. Этот шаг позволил найти наилучший баланс между точностью (precision) и полнотой (recall) для ключевого класса, что критически важно для несбалансированных данных.
