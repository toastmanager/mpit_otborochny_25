## Важные детали

- В датасете присутствуют заказы, которые были отменены даже при том условии, что цена была такой же, которую предлагал пользователь
  - Добавлена переменная для учёта этих данных

## Добавленные переменные

- bid_matches_start_price
  - бинарный признак, который показывает, совпала ли цена водителя с ценой пользователя.
  - Теперь модель сможет анализировать зависимость. Например, она может обнаружить, что когда bid_matches_start_price == 1, а заказ все равно отменяется, это часто связано с другими факторами (например, низкий рейтинг водителя или очень большое время подачи). Этот признак добавляет в модель новый пласт информации.
- price_per_meter
- price_per_second
- price_increase_abs
- price_increase_perc

- driver_experience_days
- driver_experience_years

- order_hour
- order_dayofweek
- is_night

## Удалённые переменные

- is_done - целевая колонна
- order_id
- user_id
- tender_id
- tender_timestamp
- order_timestamp
- driver_reg_date (заменена менее персональными данными)
- driver_id
- order_datetime (заменена менее персональными данными)

## Алгоритм построения и оптимизации модели

Для решения задачи классификации был разработан комплексный пайплайн, включающий несколько ключевых этапов, направленных на обеспечение высокого качества данных, подбор оптимальной конфигурации модели и предотвращение переобучения.

### 1. Предобработка и очистка данных

Начальный этап направлен на устранение ошибок и артефактов в исходном датасете для повышения его качества и консистентности. Были выполнены следующие шаги:

- Устранение артефактов вычислений: Исправлены ошибки, возникающие при делении на ноль (например, в полях price_per_meter), путем присвоения таким значениям логичного нуля.
- Удаление аномальных и нелогичных записей: Из набора данных были удалены строки с заведомо некорректными значениями, такими как отрицательный опыт водителя или поездки с практически нулевой дистанцией и длительностью.

### 2. Инженерия признаков

Для улучшения предсказательной силы модели и снижения "шума" в данных был применен метод группировки редких категорий:

- Группировка редких категорий: В категориальных признаках, таких как carmodel и carname, значения, встречающиеся в датасете менее 10 раз, были объединены в общую категорию "Other". Это позволяет модели не переобучаться на единичных, статистически незначимых примерах и находить более общие закономерности.

### 3. Подбор оптимальных гиперпараметров (Optuna)

Вместо ручного подбора "настроек" модели был использован фреймворк Optuna для автоматизированного и интеллектуального поиска.

- Интеллектуальный поиск: Optuna применяет байесовские методы оптимизации для эффективного исследования пространства гиперпараметров (learning_rate, max_depth, l2_leaf_reg и др.).

- Целевая метрика: Целью поиска была максимизация F1-score для класса 1 на отложенной валидационной выборке. Это гарантирует, что подбирается конфигурация, наилучшим образом решающая задачу выявления более редкого, но важного класса.

### 4. Обучение финальной модели (CatBoost)

В качестве основного алгоритма был выбран CatBoost — мощная реализация градиентного бустинга, обладающая рядом преимуществ.

- Обучение на лучших параметрах: Финальная модель обучалась на полной обучающей выборке с использованием лучшей комбинации гиперпараметров, найденной Optuna.

- Ранняя остановка (Early Stopping): В процессе обучения применялся механизм ранней остановки. Модель прекращала обучение, как только ее производительность на валидационной выборке переставала улучшаться в течение 50 итераций. Это позволило:

  - Избежать переобучения, повысив обобщающую способность модели.

  - Автоматически определить оптимальное количество деревьев (n_estimators), делая процесс более эффективным.

### 5. Оптимизация порога классификации (Threshold Tuning)

Финальным шагом стала тонкая настройка решающего правила модели. Вместо стандартного порога вероятности (0.5) был найден оптимальный.

- Поиск лучшего порога: Модель предсказывает вероятности принадлежности к классу 1. Был выполнен перебор пороговых значений от 0.1 до 0.9 с шагом 0.01.

- Выбор по F1-score: Был выбран тот порог, который обеспечил максимальный F1-score для класса 1 на тестовой выборке. Этот шаг позволил найти наилучший баланс между точностью (precision) и полнотой (recall) для ключевого класса, что критически важно для несбалансированных данных.

Старт обучения модели в Sat Oct 18 08:30:24 2025

--- Результаты подбора гиперпараметров Optuna ---
Лучший F1-score на валидации: 0.5867
Лучшие гиперпараметры:
learning_rate: 0.04015366750168614
max_depth: 4
l2_leaf_reg: 6.329078681235193
subsample: 0.849501012401358

--- Обучение финальной модели на лучших параметрах ---

--- Оценка финальной модели на тестовой выборке ---
Поиск оптимального порога -> Лучший F1-score для класса 1: 0.597 при пороге: 0.45
Итоговая точность (Accuracy): 0.623
Матрица ошибок:
[[2297 2012]
 [ 513 1871]]

Отчет по классификации:

```
               precision    recall  f1-score   support

           0       0.82      0.53      0.65      4309
           1       0.48      0.78      0.60      2384

    accuracy                           0.62      6693
   macro avg       0.65      0.66      0.62      6693
weighted avg       0.70      0.62      0.63      6693
```

--- Топ-15 самых важных признаков ---
feature importance
16 price_increase_perc 20.471882
15 price_increase_abs 10.566375
3 carmodel 8.586133
13 price_per_meter 6.777097
10 order_hour 6.372568
17 driver_experience_days 6.025562
0 distance_in_meters 5.473457
1 duration_in_seconds 4.966176
7 pickup_in_seconds 4.615512
2 driver_rating 4.295708
9 price_bid_local 4.105904
6 pickup_in_meters 3.956322
14 price_per_second 3.691897
4 carname 3.558208
8 price_start_local 2.654257
Конец обучения модели в Sat Oct 18 08:38:42 2025
Затрачено на обучение: 497.7903354167938 сек.

Оптимизированная модель сохранена в catboost_predictor_optimized.joblib
